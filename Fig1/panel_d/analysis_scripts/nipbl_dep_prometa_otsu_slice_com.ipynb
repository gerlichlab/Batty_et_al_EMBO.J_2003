{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analyis\n",
    "## New Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from skimage import (\n",
    "    exposure, io, morphology, measure\n",
    ")\n",
    "import math\n",
    "from scipy import signal\n",
    "from skimage.filters import threshold_multiotsu, threshold_otsu\n",
    "from glob import glob\n",
    "import shutil\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats.stats import spearmanr\n",
    "from skimage.filters import threshold_multiotsu, threshold_li\n",
    "from skimage import morphology\n",
    "from skimage.morphology import disk\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from scipy import ndimage\n",
    "from pathlib import Path\n",
    "from skimage.segmentation import watershed, clear_border\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice(im3d, savefig = False):\n",
    "    #TODO rename to slicer\n",
    "    stack_size = im3d.shape[0]\n",
    "    hist=[]\n",
    "    for i in range(stack_size):\n",
    "        hist.append(im3d[i,:,:].mean())\n",
    "    plt.plot(range(stack_size),hist, '.-')\n",
    "    #if len(signal.argrelextrema(np.array(hist), np.greater)) <= 2:\n",
    "    grad1 = np.gradient(hist)\n",
    "    peaks, ups = signal.find_peaks(grad1,max(grad1)*0.1)\n",
    "    peaks2, ups2 = signal.find_peaks(hist,max(hist)*0.1)\n",
    "    #plt.vlines([maximums],0,max(hist), colors='r')\n",
    "    plt.vlines([peaks2],0,max(hist), colors='b')\n",
    "    chosen=[]\n",
    "    for i in range(stack_size):\n",
    "        if hist[i] >= (ups['peak_heights'][0]+2*ups2['peak_heights'][0])/3:\n",
    "            plt.vlines(i,0,max(hist), colors='y')\n",
    "            chosen.append(i)\n",
    "    if savefig is True:\n",
    "        plt.savefig('slice_overview.png')\n",
    "    return chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_center_mass(im3d, savefig = False):\n",
    "    #TODO rename to slicer\n",
    "    chosen = []\n",
    "    centre_of_mass = ndimage.center_of_mass(im3d)\n",
    "    com = centre_of_mass[0]\n",
    "    if com % 1 <= 0.5:\n",
    "        centre = math.floor(com)\n",
    "        start = centre - 5\n",
    "        stop = centre + 5\n",
    "        for i in range(start, stop+1):\n",
    "            chosen.append(i)\n",
    "    else:\n",
    "        centre = math.ceil(com)\n",
    "        start = centre - 5\n",
    "        stop = centre + 5\n",
    "        for i in range(start, stop+1):\n",
    "            chosen.append(i)\n",
    "    #if savefig is True:\n",
    "        #plt.savefig('slice_overview.png')\n",
    "    return chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO different slicing strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(im3d, cmap=\"gray\", step=1, chosen = None, savefig = False):\n",
    "    if chosen is None: \n",
    "        chosen = []\n",
    "    stack_size = im3d.shape[0]\n",
    "    cols = 5\n",
    "    rows = math.ceil((stack_size/cols))\n",
    "    \n",
    "    h , axes = plt.subplots(nrows=rows, ncols=cols, figsize=(3*cols, 3*rows))\n",
    "    #print(h)\n",
    "    #p1 = get(h,'Position')\n",
    "    #annotation('rectangle',p1,'FaceAlpha',.2,'FaceColor','red','EdgeColor','red') \n",
    "    vmin = im3d.min()\n",
    "    vmax = im3d.max()\n",
    "    enum = 0\n",
    "    for ax, image in zip(axes.flatten(), im3d[::step]):\n",
    "        ax.imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        if enum in chosen:\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                #ax.spines[axis].set_linewidth(0.5)\n",
    "                ax.spines[axis].set_color(\"red\")\n",
    "                ax.spines[axis].set_linewidth(5)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        enum += 1\n",
    "    if savefig is True:\n",
    "        plt.savefig('slice_gallery.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO make saving conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_manual(im3d,start,stop, savefig = False):\n",
    "    stack_size = im3d.shape[0]\n",
    "    hist=[]\n",
    "    for i in range(stack_size):\n",
    "        hist.append(im3d[i,:,:].mean())\n",
    "    plt.plot(range(stack_size),hist, '.-')\n",
    "    #if len(signal.argrelextrema(np.array(hist), np.greater)) <= 2:\n",
    "    grad1 = np.gradient(hist)\n",
    "    peaks, ups = signal.find_peaks(grad1,max(grad1)*0.1)\n",
    "    peaks2, ups2 = signal.find_peaks(hist,max(hist)*0.1)\n",
    "    #plt.vlines([maximums],0,max(hist), colors='r')\n",
    "    plt.vlines([peaks2],0,max(hist), colors='b')\n",
    "    chosen = range(start,stop+1)\n",
    "    for i in chosen:\n",
    "        plt.vlines(i,0,max(hist), colors='y')\n",
    "    if savefig is True:\n",
    "        plt.savefig('slice_overview.png')\n",
    "    return chosen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_slice(im, cmap=\"gray\", step=1, chosen = None, savefig = False):\n",
    "    h , axes = plt.subplots(1,1)\n",
    "    vmin = im.min()\n",
    "    vmax = im.max()\n",
    "    enum = 0\n",
    "    axes.imshow(im, cmap=cmap, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO channel chooser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F-ara-EdU = channel 3, Hoechst = channel 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_size = (28.3620)\n",
    "#this is the number of pixels per micron, change the pixel size according to your specific image. You can find this out by clicking show info for the image in Fiji\n",
    "scaling_factor = pixel_size**2\n",
    "\n",
    "def slice_folder(inpath,channel,save_path,save_slice=True):\n",
    "    path = os.walk(inpath)\n",
    "    all_dataframes = []\n",
    "    #print(f\"rep:{Path(inpath).stem}\")\n",
    "    #print(f\"cond: {Path(inpath).parent.stem}\")\n",
    "    for root, directories, files in path:\n",
    "        for directory in directories:\n",
    "            #print(directory)\n",
    "            #print(os.path.join(root,directory))\n",
    "            os.chdir(os.path.join(root,directory))\n",
    "            subfiles = glob('*registered.tif', recursive=True)\n",
    "            #print(subfiles)\n",
    "            # cycles through default colors\n",
    "            #plot0 = plt.plot(0,0)\n",
    "            #cond0_color = plot0[0].get_color()   \n",
    "            for file in subfiles:\n",
    "                data = io.imread(os.path.join(root,directory,file))\n",
    "                channel_data = data[:,:,:,channel-1]\n",
    "                os.chdir(os.path.join(root,directory))\n",
    "                chosen = slice_center_mass(channel_data, savefig = True)\n",
    "                if (save_slice is True):\n",
    "                    display(channel_data, chosen=chosen, savefig = True)\n",
    "                #print(os.path.join(root,directory,file))\n",
    "                print(file)\n",
    "                print(chosen)\n",
    "                all_coeff = []\n",
    "                all_pvalue = []\n",
    "                all_slice = []\n",
    "                all_area = []\n",
    "                if not os.path.exists(os.path.join(root,directory,\"slices\")):\n",
    "                    os.mkdir(os.path.join(root,directory,\"slices\"))\n",
    "                for slicing in chosen:\n",
    "                    if not os.path.exists(os.path.join(root,directory,\"slices\", str(slicing))):\n",
    "                        os.mkdir(os.path.join(root,directory,\"slices\", str(slicing)))\n",
    "                    os.chdir(os.path.join(root,directory,\"slices\", str(slicing)))\n",
    "                    filestring = file[:-4] + \"_slice_\" + str(slicing) + \".tif\"\n",
    "                    filestring_mask = file[:-4] + \"_maskotsu_\" + str(slicing) + \".tif\"\n",
    "                    #print(filestring)\n",
    "                    #TODO: Make the channels choosable\n",
    "                    data_edu = data[slicing,:,:,2]\n",
    "                    data_hoechst = data[slicing,:,:,3]\n",
    "                    # The input image.\n",
    "                    image = data_hoechst\n",
    "\n",
    "                    #otsu thresholding to generate binary mask\n",
    "                    thresh = threshold_otsu(image)\n",
    "                    #generate mask\n",
    "                    mask = image > thresh\n",
    "\n",
    "                    #Clear borders, get rid of cells which touch the edge of the image\n",
    "                    cleared = clear_border(mask)\n",
    "\n",
    "                    #get rid of the edge cases in the regions of interest, exclude things which are in regions but not in the cleared mask\n",
    "                    #cleared_regions = np.logical_and(regions, cleared)\n",
    "                    \n",
    "                    #remove debris and other small objects below a certain size e.g. micronuclei\n",
    "                    remove_debris = morphology.remove_small_objects(cleared, 3200)\n",
    "                    \n",
    "                    #set labels \n",
    "                    labels = measure.label(remove_debris)\n",
    "                    #Measure properties\n",
    "                    #set properties\n",
    "                    props = measure.regionprops(labels)\n",
    "                                                          \n",
    "                    #create the csv data:\n",
    "                    flat_edu = data_edu.flatten()\n",
    "                    flat_hoechst = data_hoechst.flatten()\n",
    "                    flat_cleared_remove_debris = remove_debris.flatten()\n",
    "                    all_data = pd.DataFrame(zip(flat_edu,flat_hoechst, flat_cleared_remove_debris),columns=[\"edu\",\"hoechst\", \"cleared\"])\n",
    "\n",
    "                    #filter relevant data into new dataframe. Only values which are in cleared and also in regions chosen.\n",
    "\n",
    "                    regions_filtered_data = all_data[all_data[\"cleared\"] == True]\n",
    "                    \n",
    "                    #calculate area of nucleus, convert back to pixels, as a quality control for the thresholding, if the area is super low then the main mask touches the edge and was cleared in the clear borders step\n",
    "                    cleared_area = 0\n",
    "                    for i in range(len(props)):\n",
    "                        #print((props[i].area))\n",
    "                        cleared_area += props[i].area\n",
    "                        nuclear_area = cleared_area/scaling_factor    \n",
    "                        \n",
    "                    #perform correlation\n",
    "                    correlation_coeff, pvalue = spearmanr(regions_filtered_data[\"hoechst\"], regions_filtered_data[\"edu\"])\n",
    "                    all_coeff.append(correlation_coeff)\n",
    "                    all_pvalue.append(pvalue) \n",
    "                    all_slice.append(slicing)\n",
    "                    all_area.append(nuclear_area)\n",
    "                    #print(correlation_coeff)\n",
    "                    if (save_slice is True):\n",
    "                        io.imsave(filestring,data[slicing,:,:,:])\n",
    "                        io.imsave(filestring_mask,remove_debris[:,:])\n",
    "                single_df = pd.DataFrame(list(zip(all_coeff,all_pvalue,all_slice, all_area)),columns=[\"correlation_coeff\", \"pvalue\", \"slice\", \"area\"])\n",
    "                single_df['image'] = file\n",
    "                single_df =  single_df[['image', 'area', 'slice', 'correlation_coeff', 'pvalue']]\n",
    "                all_dataframes.append(single_df)\n",
    "    final_df = pd.concat(all_dataframes)\n",
    "    mean = final_df.groupby(['image'], as_index=False)[['area', 'correlation_coeff']].mean()\n",
    "    #final_df = final_df.loc[['image', 'mean_scc']]\n",
    "    #calculate_mean_df = pd.DataFrame(mean)\n",
    "    if save_path is not None:\n",
    "        print(\"SAVED\")\n",
    "        replicate = Path(inpath).stem\n",
    "        cond = Path(inpath).parent.stem\n",
    "        #final_df.csv(f'{save_path}/{cond}_{replicate}slices.csv', index = False)\n",
    "        mean.to_csv(f'{save_path}/{cond}_{replicate}.csv', index=False)\n",
    "    plt.close(\"all\")\n",
    "##TODO fix file keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if slicing doesn't give the expected result, then you can manually slice the cells using this function, by inputting an inpath, a channel to slice, and start and stop slices\n",
    "def slice_image(inpath,savepath, channel,start,stop):\n",
    "    print(inpath)\n",
    "    path = inpath\n",
    "    os.chdir(path)\n",
    "    file = glob('*registered.tif', recursive=True)[0]\n",
    "    data = io.imread(os.path.join(path,file))\n",
    "    channel_data = data[:,:,:,channel-1]\n",
    "    chosen = slice_manual(channel_data, start, stop, savefig = True)\n",
    "    display(channel_data, chosen=chosen, savefig = True)\n",
    "    all_coeff = []\n",
    "    all_pvalue = []\n",
    "    all_slice = []\n",
    "    if os.path.exists(os.path.join(path,\"mslices\")):\n",
    "        shutil.rmtree(os.path.join(path,\"mslices\"))\n",
    "    if not os.path.exists(os.path.join(path,\"mslices\")):\n",
    "        os.mkdir(os.path.join(path,\"mslices\"))\n",
    "    for slicing in chosen:\n",
    "        if not os.path.exists(os.path.join(path,\"mslices\", str(slicing))):\n",
    "            os.mkdir(os.path.join(path,\"mslices\", str(slicing)))\n",
    "        os.chdir(os.path.join(path,\"mslices\", str(slicing)))\n",
    "        filestring = file[:-4] + \"_slice_\" + str(slicing) + \".tif\"\n",
    "        io.imsave(filestring,data[slicing,:,:,:])\n",
    "        data_edu = data[slicing,:,:,2]\n",
    "        data_hoechst = data[slicing,:,:,3]\n",
    "        # The input image.\n",
    "        image = data_hoechst\n",
    "\n",
    "        thresh = threshold_li(image)\n",
    "        #remove small holes by performing closing. Binary_closing faster for binary images.\n",
    "        binary_mask = morphology.binary_closing(image > thresh, disk(5))\n",
    "\n",
    "        #remove edge artefacts with cleared\n",
    "        #cleared = segmentation.clear_border(binary_mask)\n",
    "\n",
    "        #erode binary mask with disk size of 20\n",
    "        eroded = morphology.erosion(binary_mask, disk(20))\n",
    "\n",
    "        #crerate the csv data:\n",
    "        flat_edu = data_edu.flatten()\n",
    "        flat_hoechst = data_hoechst.flatten()\n",
    "        flat_eroded = eroded.flatten()\n",
    "        all_data = pd.DataFrame(zip(flat_edu,flat_hoechst,flat_eroded),columns=[\"edu\",\"hoechst\",\"eroded\"])\n",
    "        #filter relevant data\n",
    "        regions_filtered_data = all_data.loc[all_data.eroded == True]\n",
    "        #perform correlation\n",
    "        correlation_coeff, pvalue = spearmanr(regions_filtered_data[\"hoechst\"], regions_filtered_data[\"edu\"])\n",
    "        all_coeff.append(correlation_coeff)\n",
    "        all_pvalue.append(pvalue) \n",
    "        all_slice.append(slicing)\n",
    "        #print(correlation_coeff)\n",
    "        #if (save_slice is True):\n",
    "            #io.imsave(filestring,data[slicing,:,:,:])\n",
    "    single_df = pd.DataFrame(list(zip(all_coeff,all_pvalue,all_slice)),columns=[\"correlation_coeff\", \"pvalue\", \"slice\"])\n",
    "    single_df['image'] = file\n",
    "    single_df =  single_df[['image', 'slice', 'correlation_coeff', 'pvalue']]\n",
    "    #all_dataframes.append(single_df)\n",
    "    #final_df = pd.concat(all_dataframes)\n",
    "    if savepath is not None:\n",
    "        print(\"SAVED\")\n",
    "        #replicate = Path(inpath).stem\n",
    "        #cond = Path(inpath).parent.stem\n",
    "        single_df.to_csv(f'{savepath}/{file}.csv', index = False)\n",
    "    plt.close(\"all\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The manual slice_image will create a folder mslice instead to show that these were taken manually. Rerunning with different parameters will remove the previous content of the mslice folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply to the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2045_nipbl_dep_prometa_two_sister',\n",
       " '2045_nipbl_dep_prophase_early_one_sister',\n",
       " '2045_nipbl_dep_prophase_late_one_sister',\n",
       " '2045_nipbl_dep_prophase_mid_one_sister']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = \"/groups/gerlich/experiments/Experiments_005500/005530/tifs_registered_background_subtracted_testing/2045_nipbl_aid_prometa/\"\n",
    "conditions = next(os.walk(base_path))[1]\n",
    "#remove hidden folder created by jupyter:\n",
    "clean_conditions = [c for c in conditions if not re.match(r'^\\.', c)]\n",
    "conditions = sorted(clean_conditions)\n",
    "conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nipbl = [c for c in conditions if re.match(r'2045', c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONDITION: 2045_nipbl_dep_prometa_two_sister\n",
      "REPLICATES: ['5389']\n",
      "/groups/gerlich/experiments/Experiments_005500/005530/tifs_registered_background_subtracted_testing/2045_nipbl_aid_prometa/2045_nipbl_dep_prometa_two_sister/5389\n",
      "220207_5389_2045_nipbl_dep_c1_rep1_60min_stlc_fully_zoom5-03-01.czi #1.tif_registered.tif\n",
      "[52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62]\n",
      "220207_5389_2045_nipbl_dep_c1_rep1_60min_stlc_fully_zoom5-03-01.czi #2.tif_registered.tif\n",
      "[46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
      "220207_5389_2045_nipbl_dep_c1_rep1_60min_stlc_fully_zoom5-03-01.czi #3.tif_registered.tif\n",
      "[47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57]\n",
      "220207_5389_2045_nipbl_dep_c1_rep1_60min_stlc_fully_zoom5-03-01.czi #4.tif_registered.tif\n",
      "[54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]\n",
      "220207_5389_2045_nipbl_dep_c1_rep2_60min_stlc_fully_zoom5-02.czi #1.tif_registered.tif\n",
      "[45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]\n",
      "220207_5389_2045_nipbl_dep_c1_rep2_60min_stlc_fully_zoom5-02.czi #2.tif_registered.tif\n",
      "[45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]\n",
      "220207_5389_2045_nipbl_dep_c1_rep2_60min_stlc_fully_zoom5-02.czi #3.tif_registered.tif\n",
      "[50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n",
      "220207_5389_2045_nipbl_dep_c1_rep2_60min_stlc_fully_zoom5-02.czi #4.tif_registered.tif\n",
      "[46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
      "220207_5389_2045_nipbl_dep_c2_rep1_60min_stlc_fully_zoom5-01-03.czi #1.tif_registered.tif\n",
      "[58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68]\n",
      "220207_5389_2045_nipbl_dep_c2_rep1_60min_stlc_fully_zoom5-01-03.czi #2.tif_registered.tif\n",
      "[54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]\n",
      "220207_5389_2045_nipbl_dep_c2_rep1_60min_stlc_fully_zoom5-03-04.tif_registered.tif\n",
      "[44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54]\n",
      "220207_5389_2045_nipbl_dep_c2_rep1_60min_stlc_fully_zoom5-04-05.tif_registered.tif\n",
      "[49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
      "220207_5389_2045_nipbl_dep_c2_rep2_60min_stlc_fully_zoom5--01-06.czi #1.tif_registered.tif\n",
      "[49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
      "220207_5389_2045_nipbl_dep_c2_rep2_60min_stlc_fully_zoom5--01-06.czi #2.tif_registered.tif\n",
      "[52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62]\n",
      "220207_5389_2045_nipbl_dep_c2_rep2_60min_stlc_fully_zoom5--01-06.czi #4.tif_registered.tif\n",
      "[46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
      "220207_5389_2045_nipbl_dep_c2_rep2_60min_stlc_fully_zoom5--01-06.czi #3.tif_registered.tif\n",
      "[42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52]\n",
      "220207_5389_2045_nipbl_dep_c2_rep2_60min_stlc_fully_zoom5--01-06.czi #5.tif_registered.tif\n",
      "[43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "SAVED\n",
      "CONDITION: 2045_nipbl_dep_prophase_early_one_sister\n",
      "REPLICATES: ['5389']\n",
      "/groups/gerlich/experiments/Experiments_005500/005530/tifs_registered_background_subtracted_testing/2045_nipbl_aid_prometa/2045_nipbl_dep_prophase_early_one_sister/5389\n",
      "220207_5389_2045_nipbl_dep_prophase_c2_rep1_60min_stlc_hemi_zoom5-01-15.czi #5.tif_registered.tif\n",
      "[33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]\n",
      "220207_5389_2045_nipbl_dep_prophase_c2_rep1_60min_stlc_hemi_zoom5-01-15.czi #7.tif_registered.tif\n",
      "[33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]\n",
      "220207_5389_2045_nipbl_dep_prophase_c1_rep1_60min_stlc_hemi_zoom5-04-13.czi #01.tif_registered.tif\n",
      "[34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n",
      "220207_5389_2045_nipbl_dep_prophase_c1_rep1_60min_stlc_hemi_zoom5-04-13.czi #08.tif_registered.tif\n",
      "[28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\n",
      "220207_5389_2045_nipbl_dep_prophase_c1_rep1_60min_stlc_hemi_zoom5-04-13.czi #09.tif_registered.tif\n",
      "[33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]\n",
      "SAVED\n",
      "CONDITION: 2045_nipbl_dep_prophase_late_one_sister\n",
      "REPLICATES: ['5389']\n",
      "/groups/gerlich/experiments/Experiments_005500/005530/tifs_registered_background_subtracted_testing/2045_nipbl_aid_prometa/2045_nipbl_dep_prophase_late_one_sister/5389\n",
      "220207_5389_2045_nipbl_dep_prophase_c2_rep1_60min_stlc_hemi_zoom5-01-15.czi #3.tif_registered.tif\n",
      "[27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]\n",
      "220207_5389_2045_nipbl_dep_prophase_c2_rep1_60min_stlc_hemi_zoom5-01-15.czi #6.tif_registered.tif\n",
      "[29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "220207_5389_2045_nipbl_dep_prophase_c1_rep1_60min_stlc_hemi_zoom5-04-13.czi #05.tif_registered.tif\n",
      "[27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]\n",
      "220207_5389_2045_nipbl_dep_prophase_c1_rep1_60min_stlc_hemi_zoom5-04-13.czi #07.tif_registered.tif\n",
      "[31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]\n",
      "220207_5389_2045_nipbl_dep_prophase_c1_rep1_60min_stlc_hemi_zoom5-04-13.czi #10.tif_registered.tif\n",
      "[28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\n",
      "220207_5389_2045_nipbl_dep_prophase_c1_rep1_60min_stlc_hemi_zoom5-04-13.czi #11.tif_registered.tif\n",
      "[29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "220207_5389_2045_nipbl_dep_prophase_c1_rep1_60min_stlc_hemi_zoom5-04-13.czi #12.tif_registered.tif\n",
      "[27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]\n",
      "220207_5389_2045_nipbl_dep_prophase_c1_rep2_60min_stlc_hemi_zoom5-03-14.czi #2.tif_registered.tif\n",
      "[28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\n",
      "220207_5389_2045_nipbl_dep_prophase_c1_rep2_60min_stlc_hemi_zoom5-03-14.czi #9.tif_registered.tif\n",
      "[22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "220207_5389_2045_nipbl_dep_prophase_c2_rep1_60min_stlc_hemi_zoom5-01-15.czi #1.tif_registered.tif\n",
      "[33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]\n",
      "220207_5389_2045_nipbl_dep_prophase_c2_rep1_60min_stlc_hemi_zoom5-01-15.czi #2.tif_registered.tif\n",
      "[31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]\n",
      "SAVED\n",
      "CONDITION: 2045_nipbl_dep_prophase_mid_one_sister\n",
      "REPLICATES: ['5389']\n",
      "/groups/gerlich/experiments/Experiments_005500/005530/tifs_registered_background_subtracted_testing/2045_nipbl_aid_prometa/2045_nipbl_dep_prophase_mid_one_sister/5389\n",
      "220207_5389_2045_nipbl_dep_prophase_c1_rep2_60min_stlc_hemi_zoom5-03-14.czi #7.tif_registered.tif\n",
      "[26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36]\n",
      "220207_5389_2045_nipbl_dep_prophase_c2_rep1_60min_stlc_hemi_zoom5-01-15.czi #4.tif_registered.tif\n",
      "[28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\n",
      "220207_5389_2045_nipbl_dep_prophase_c1_rep1_60min_stlc_hemi_zoom5-04-13.czi #02.tif_registered.tif\n",
      "[34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n",
      "220207_5389_2045_nipbl_dep_prophase_c1_rep1_60min_stlc_hemi_zoom5-04-13.czi #04.tif_registered.tif\n",
      "[35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220207_5389_2045_nipbl_dep_prophase_c1_rep1_60min_stlc_hemi_zoom5-04-13.czi #06.tif_registered.tif\n",
      "[31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]\n",
      "220207_5389_2045_nipbl_dep_prophase_c1_rep2_60min_stlc_hemi_zoom5-03-14.czi #1.tif_registered.tif\n",
      "[26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36]\n",
      "220207_5389_2045_nipbl_dep_prophase_c1_rep2_60min_stlc_hemi_zoom5-03-14.czi #4.tif_registered.tif\n",
      "[28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\n",
      "220207_5389_2045_nipbl_dep_prophase_c1_rep2_60min_stlc_hemi_zoom5-03-14.czi #6.tif_registered.tif\n",
      "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n",
      "SAVED\n"
     ]
    }
   ],
   "source": [
    "for condition in nipbl:\n",
    "    replicates = next(os.walk(os.path.join(base_path,condition)))[1]\n",
    "    clean_replicates = [c for c in replicates if not re.match(r'^\\.', c)]\n",
    "    replicates = sorted(clean_replicates)\n",
    "    print(f'CONDITION: {condition}')\n",
    "    print(f'REPLICATES: {replicates}')\n",
    "    for replicate in replicates:\n",
    "        folder_to_slice = os.path.join(base_path,condition,replicate)\n",
    "        print(folder_to_slice)\n",
    "        slice_folder(folder_to_slice, 3,  \"/groups/gerlich/members/PaulBatty/Paper_preparation/slicer_com/quantification/results/otsu_mid11_remove_debris/\")      \n",
    "        #pass\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5a7911856c62930073f5a12692b60e69b2279f75f68a53f59a0bc7e438cc0fc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
