{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook various conditions will be compared in order to generate insights into the role of loop extrusion and diffusion on the resolution of sister chromatids.\n",
    "    \n",
    "The conditions to be compared will be conditions where <b> cohesin loop extrusion is absent (NIPBL depletion, Scc1 depletion)<b> or <b>cohesin loop extrusion occurs with normal turnover kinetics (G2_WT, CTCF_depletion, Sororin_depletion)<b>\n",
    "    \n",
    "    \n",
    "To compare the influence of increased cohesin loop extrusion with other perturbations, a second notebook will be prepared.\n",
    "    \n",
    "Note, in order to more precisely calculate the cis/trans ratio, a larger number of ndistbins are used in the scaling plot calculation (60 rather than 40).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sbn\n",
    "import os\n",
    "import pairlib.scalings\n",
    "import pairlib\n",
    "import bioframe\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import subprocess\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.ticker as mtick\n",
    "from scipy.interpolate import interp1d, splev, CubicSpline, PPoly\n",
    "import scipy.integrate as spi\n",
    "#import metpy\n",
    "import pathlib\n",
    "\n",
    "from ngs import HiCTools as HT\n",
    "\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from scipy import ndimage as ndi\n",
    "import skimage\n",
    "from skimage import io, filters, morphology\n",
    "import glob\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.signal import chirp, find_peaks, peak_widths, savgol_filter\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import scipy.stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATTENTION: You need to run a high memory kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Figure out why this des not work for pbgzip!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/conda/bin/lz4c'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.which('pbgzip')   \n",
    "shutil.which('lz4c')\n",
    "\n",
    "#Since pairtools/_fileio.py checks for this\n",
    "#if shutil.which('pbgzip') is None:\n",
    "#            raise ValueError({\n",
    "#                'w':'pbgzip is not found, cannot compress output',\n",
    "#                'a':'pbgzip is not found, cannot compress output',\n",
    "#                'r':'pbgzip is not found, cannot decompress input'\n",
    "#                    }[mode])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: I made a copy of ther *pairs.gz into unzip/ (to be save because our gzip version is <1.6 and has no -k flag). And this script now only works with unzipped pairsam files until IT installs pbgzip since in the jupyter kernel will not find the version installed with conda. Or we rewrite Antons tool to use a different bzip. (would be in pairtools/_fileio.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairDir = {\"wt_TTAGGC_S2\": \"/groups/gerlich/experiments/Experiments_005600/005679/paper_merging_replicates/wild_type/unzipped/\",\n",
    "           \"wt_CAGATC_S3\": \"/groups/gerlich/experiments/Experiments_005600/005679/paper_merging_replicates/wild_type/unzipped/\",\n",
    "           \"wt_ACTTGA_S4\": \"/groups/gerlich/experiments/Experiments_005600/005679/paper_merging_replicates/wild_type/unzipped/\",\n",
    "           \"wt_GATCAG_S5\": \"/groups/gerlich/experiments/Experiments_005600/005679/paper_merging_replicates/wild_type/unzipped/\",\n",
    "           \"wt_TAGCTT_S6\": \"/groups/gerlich/experiments/Experiments_005600/005679/paper_merging_replicates/wild_type/unzipped/\",\n",
    "           \"wt_AGTCAA_S7\": \"/groups/gerlich/experiments/Experiments_005600/005679/paper_merging_replicates/wild_type/unzipped/\",\n",
    "           \"wt_AGTTCC_S8\": \"/groups/gerlich/experiments/Experiments_005600/005679/paper_merging_replicates/wild_type/unzipped/\",\n",
    "           \"wt_ATGTCA_S9\": \"/groups/gerlich/experiments/Experiments_005600/005679/paper_merging_replicates/wild_type/unzipped/\",\n",
    "           \"wt_CCGTCC_S10\": \"/groups/gerlich/experiments/Experiments_005600/005679/paper_merging_replicates/wild_type/unzipped/\", \n",
    "           \"wt_GCCAAT\" : \"/groups/gerlich/experiments/Experiments_005600/005679/paper_merging_replicates/wild_type/unzipped/\",\n",
    "           \"wt_GTGAAA\" : \"/groups/gerlich/experiments/Experiments_005600/005679/paper_merging_replicates/wild_type/unzipped/\"\n",
    "          }\n",
    "\n",
    "\n",
    "sampleMapping = {\"wt_GCCAAT\" : \"G2_WT_rep1\",\n",
    "                 \"wt_TTAGGC_S2\": \"G2_WT_rep2\",\n",
    "                 \"wt_CAGATC_S3\": \"G2_WT_rep3\",\n",
    "                 \"wt_ACTTGA_S4\": \"G2_WT_rep4\",\n",
    "                 \"wt_GATCAG_S5\": \"G2_WT_rep5\",\n",
    "                 \"wt_TAGCTT_S6\": \"G2_WT_rep6\",\n",
    "                 \"wt_AGTCAA_S7\": \"G2_WT_rep7\",\n",
    "                 \"wt_AGTTCC_S8\": \"G2_WT_rep8\",\n",
    "                 \"wt_ATGTCA_S9\": \"G2_WT_rep9\",\n",
    "                 \"wt_CCGTCC_S10\": \"G2_WT_rep10\",\n",
    "                 \"wt_GTGAAA\" : \"G2_WT_rep11\"\n",
    "                 }\n",
    "\n",
    "\n",
    "pairs = {}\n",
    "for barcode, name in sampleMapping.items():\n",
    "    pairs[name] = {}\n",
    "    pairs[name][\"cis\"] = HT.load_pairs(\n",
    "        os.path.join(pairDir[barcode], f\"{barcode}.cis.pairs\"))\n",
    "    pairs[name][\"trans\"] = HT.load_pairs(\n",
    "        os.path.join(pairDir[barcode], f\"{barcode}.trans.pairs\"))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prepare data for plotting<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndistbins set to 60 instead of 40 to more accurately calculate the interesection point in cis/trans ratio plots\n",
    "# downsample pairs --> use this if you have multiple samples\n",
    "# then pairs needs to be a nested dictionary {sample: {cis: pairFrame, trans:pairFrame}}\n",
    "\n",
    "downsampled = HT.down_sample_pairs(pairs, distance=1000)\n",
    "\n",
    "# get chromosome features\n",
    "\n",
    "hg19_chromsizes = bioframe.fetch_chromsizes('hg19')\n",
    "arms = HT.get_arms_hg19()\n",
    "\n",
    "# calculate scaling plots\n",
    "\n",
    "scs = {sample: {rType: pairlib.scalings.compute_scaling(\n",
    "       downsampled[sample][rType],\n",
    "       arms,\n",
    "       hg19_chromsizes, n_dist_bins=40\n",
    "       ) for rType in [\"cis\", \"trans\"]}\n",
    "       for sample in downsampled.keys()}\n",
    "\n",
    "\n",
    "# aggregate scaling plots\n",
    "\n",
    "sc_agg = {sample: {rType: (scs[sample][rType][0]\n",
    "                  .groupby(['min_dist', 'max_dist'])\n",
    "                  .agg({'n_pairs': 'sum', 'n_bp2': 'sum'})\n",
    "                  .reset_index())\n",
    "          for rType in scs[sample].keys()\n",
    "          } for sample in scs.keys()\n",
    "          }\n",
    "\n",
    "# calculate x-Values and contact probability\n",
    "\n",
    "plotData = {sample: {rType: (np.sqrt(sc_agg[sample][rType].min_dist * sc_agg[sample][rType].max_dist),\n",
    "            sc_agg[sample][rType].n_pairs / sc_agg[sample][rType].n_bp2)\n",
    "            for rType in sc_agg[sample].keys()\n",
    "            } for sample in sc_agg.keys()\n",
    "                        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup apearance for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colormap for plots\n",
    "colorMap = {\"cis\": \"gray\",\n",
    "            \"trans\": \"black\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot cis and trans per condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in plotData.keys():\n",
    "    f, ax = plt.subplots(1,1)\n",
    "    for rType in [\"cis\", \"trans\"]:\n",
    "        ax.loglog(plotData[sample][rType][0],\n",
    "                plotData[sample][rType][1],\n",
    "                label=f'{rType.capitalize()}', color=colorMap[rType], lw=3\n",
    "                )\n",
    "    ax.grid(lw=0.5, color='gray')\n",
    "    ax.grid(False)\n",
    "    ax.set_xlim(10000, 100000000)\n",
    "    ax.set_ylim(10**(-15), 10**(-8))\n",
    "    ax.legend(frameon=False)\n",
    "    ax.set_xlabel(\"Genomic Distance,bp\")\n",
    "    ax.set_ylabel(\"Contact Probability\")\n",
    "    f.set_size_inches(5, 5)\n",
    "    sbn.despine()\n",
    "    plt.title(sample)\n",
    "    f.show()\n",
    "    #resultsdir = \"/groups/gerlich/experiments/Experiments_004800/004885/Results\"\n",
    "    #f.savefig(os.path.join(resultsdir, f\"{sample}Scaling_plot.png\"), bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe from scalings, interpolate the data using cubic spline interpolation and create dataframes as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in plotData.keys():\n",
    "    for rtype in [\"cis\"], [\"trans\"]:\n",
    "        #make dataframes from scalings\n",
    "        bins = plotData[sample][\"cis\"][0]\n",
    "        cis = plotData[sample][\"cis\"][1]\n",
    "        trans = plotData[sample][\"trans\"][1]\n",
    "        ratio = plotData[sample][\"cis\"][1]/plotData[sample][\"trans\"][1]\n",
    "        series_list = (bins, cis, trans, ratio)\n",
    "        cis_trans_ratios = pd.concat(series_list, axis=1)\n",
    "        cis_trans_ratios.columns = ['bins', 'cis_contact_prob', 'trans_contact_prob','cis/trans_ratio']\n",
    "        cis_trans_ratios[\"condition\"] = f'{sample}'\n",
    "        #remove last row\n",
    "        cis_trans_ratios = cis_trans_ratios.iloc[:-1 , :]\n",
    "        resultsdir = \"/groups/gerlich/members/PaulBatty/Paper_preparation/figures/dropbox/fig5/interpolate_values_per_condition/input/3a/\"\n",
    "        cis_trans_ratios.to_csv(os.path.join(resultsdir, f\"{sample}.csv\"), index=False)\n",
    "        \n",
    "               \n",
    "        #interpolation\n",
    "        #select all non NaN values\n",
    "        genomic_distance = cis_trans_ratios.loc[17:32, \"bins\"]\n",
    "        ratio = cis_trans_ratios.loc[17:32, \"cis/trans_ratio\"]\n",
    "        \n",
    "        #perform interpolation using cubic spline\n",
    "        interpolate = CubicSpline(genomic_distance, ratio, bc_type='natural')\n",
    "        # start value, stop value, number of points to interpolate in between\n",
    "        genomic_distance_new = np.linspace(12000, 25000000, 100000)\n",
    "        ratio_new = interpolate(genomic_distance_new)\n",
    "        ratio_new = savgol_filter(ratio_new, 11, 3)\n",
    "        #create series to make dataframe        \n",
    "        series1 = pd.Series(genomic_distance_new)\n",
    "        series2 = pd.Series(ratio_new)\n",
    "        series_list = (series1, series2)\n",
    "        #concatentate series to make a dataframe\n",
    "        df = pd.concat(series_list, axis=1)\n",
    "        #rename columns\n",
    "        df.columns = ['genomic_distance_interpolated','ratio_interpolated']\n",
    "        df[\"condition\"] = f'{sample}'\n",
    "        resultsdir = \"/groups/gerlich/members/PaulBatty/Paper_preparation/figures/dropbox/fig5/interpolate_values_per_condition/interpolated/3a/\"\n",
    "        df.to_csv(os.path.join(resultsdir, f\"{sample}_interpolated_data.csv\"), index=False)\n",
    "        \n",
    "        #plot data\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(20,6))\n",
    "        ax1.set_xlabel('Genomic distance')\n",
    "        ax1.set_ylabel('Cis/trans ratio')\n",
    "        ax2.set_xlabel('Genomic distance')\n",
    "        ax2.set_ylabel('Cis/trans ratio')\n",
    "        ax1.plot(genomic_distance_new, ratio_new, 'b')\n",
    "        ax1.plot(genomic_distance, ratio, 'ro')\n",
    "        ax2.semilogx(genomic_distance_new, ratio_new, 'b')\n",
    "        ax2.semilogx(genomic_distance, ratio, 'ro')\n",
    "\n",
    "        ax1.set_title(f\"{sample} linear x\")\n",
    "        ax2.set_title(f\"{sample} logarithmic x\")\n",
    "        plt.show()\n",
    "        resultsdir = \"/groups/gerlich/members/PaulBatty/Paper_preparation/figures/dropbox/fig5/interpolate_values_per_condition/plots/3a/\"\n",
    "        fig.savefig(os.path.join(resultsdir, f\"{sample}_interpolated_data.csv.png\"), bbox_inches=\"tight\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in interpolated data, get interpolated genomic distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write function to find the first instance where the cis/trans ratio goes below a threshold value\n",
    "# set threshold value to 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first(threshold, input1, input2):\n",
    "    #find the first instance where the cis/trans ratio goes below a threshold value\n",
    "    for i in range(len(input1)):\n",
    "        if input1[i] < threshold:\n",
    "            return i-1, input1[i-1], input2[i-1]\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for result in results:\n",
    "    #dataframes = pd.read_csv(result)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in dataframes - pass function to each one and get out the interpolate values\n",
    "path = \"/groups/gerlich/members/PaulBatty/Paper_preparation/figures/dropbox/fig5/interpolate_values_per_condition/interpolated/3a/\"\n",
    "\n",
    "csv_files = glob.glob(path + \"/*.csv\")\n",
    "### Fetch all files in path\n",
    "\n",
    "#head, tail = os.path.split(path_lateprophase)\n",
    "#set up empty lists to append\n",
    "threshold = 1.25\n",
    "\n",
    "all_intersect_distance = []\n",
    "all_condition = []\n",
    "\n",
    "for file in csv_files:\n",
    "    split = file.split(os.sep)\n",
    "    name = split[-1]\n",
    "    #print (name)\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    #get inputs\n",
    "    input1 = df[\"ratio_interpolated\"]\n",
    "    input2 = df[\"genomic_distance_interpolated\"]\n",
    "    condition_slice = df[\"condition\"]\n",
    "    condition = condition_slice.iloc[0]\n",
    "    \n",
    "    #feed into function\n",
    "    function = find_first(threshold, input1, input2)\n",
    "    intersect_distance = function[2]\n",
    "    #append to lists\n",
    "    all_intersect_distance.append(intersect_distance)\n",
    "    all_condition.append(condition)\n",
    "    \n",
    "#set results directory\n",
    "resultsdir = \"/groups/gerlich/members/PaulBatty/Paper_preparation/figures/dropbox/fig5/interpolate_values_per_condition/\"\n",
    "\n",
    "#zip the data to make a dataframe\n",
    "output = pd.DataFrame(list(zip(all_condition, all_intersect_distance)),columns=['condition', 'genomic_distance_intersect'])\n",
    "final_output = output.set_index(['condition'])\n",
    "final_output.to_csv(resultsdir + \"genomic_distance_intersect.csv\")\n",
    "\n",
    "final_output\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cooltools_kernel",
   "language": "python",
   "name": "cooltools_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
